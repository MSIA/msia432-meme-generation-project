{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "jupytext": {
      "comment_magics": false,
      "formats": "ipynb,py:percent"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "assignment2b_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "australian-jacob"
      },
      "source": [
        "# Assignment2b - V.2"
      ],
      "id": "australian-jacob"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "closing-boating"
      },
      "source": [
        "import os\n",
        "import sys, time, random, gc, socket\n",
        "import logging\n",
        "from collections import Counter\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from skimage.exposure import equalize_adapthist\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import LSTM, Conv2D, Bidirectional, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import get_file"
      ],
      "id": "closing-boating",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sticky-examination",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf603251-3e38-4d1e-8949-703c0db5917e"
      },
      "source": [
        "try:\n",
        "    # tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "else:\n",
        "  print('NUM GPUS:', len(tf.config.list_physical_devices('GPU')))"
      ],
      "id": "sticky-examination",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUM GPUS: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "compressed-settlement"
      },
      "source": [
        "logger = logging.getLogger('my_happy_logger')\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\n",
        "\n",
        "stream_handler = logging.StreamHandler()\n",
        "stream_handler.setFormatter(formatter)\n",
        "\n",
        "logger.addHandler(stream_handler)"
      ],
      "id": "compressed-settlement",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "great-while"
      },
      "source": [
        "# GPU memory fix + Mac workaround\n",
        "if not IS_COLAB:\n",
        "    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
        "    os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
      ],
      "id": "great-while",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "every-stamp"
      },
      "source": [
        "os.makedirs('textgen-figures', exist_ok=True)"
      ],
      "id": "every-stamp",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frank-criterion"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "id": "frank-criterion",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ignored-thursday"
      },
      "source": [
        "class assign2:\n",
        "    \n",
        "    def __init__(self, filename='nietzsche.txt', \n",
        "                 filepath='https://s3.amazonaws.com/text-datasets/nietzsche.txt'):\n",
        "        \n",
        "        # saving static variables in __init__\n",
        "        self.text = self.download_file(filename, filepath)\n",
        "        self.chars = dict(sorted(Counter(self.text).items(), key=lambda x:x[1], reverse=True)).keys()\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "        \n",
        "        # dyanmic variables - these are the variables that need to be changed via clear() after each modeling process\n",
        "        self.charmap = None\n",
        "        self.hmap = None\n",
        "        self.model = None\n",
        "        \n",
        "    def download_file(self, filename, filepath):\n",
        "        path = get_file(filename, filepath)\n",
        "        text = open(path).read().lower()\n",
        "        logger.debug(f'corpus length: {len(text)}')\n",
        "        return text\n",
        "        \n",
        "    def tokenize(self, maxlen, step):\n",
        "        \n",
        "        # break text into equal-length chunks\n",
        "        char_chunks = [self.text[i: i + maxlen] for i in range(0, len(self.text) - maxlen, step)]\n",
        "        next_char = [self.text[i + maxlen] for i in range(0, len(self.text) - maxlen, step)]\n",
        "        logger.debug(f'nb sequences: {len(char_chunks)}')\n",
        "        \n",
        "        return char_chunks, next_char\n",
        "        \n",
        "    def vectorize(self, maxlen, step):\n",
        "        char_chunks, next_char = self.tokenize(maxlen, step)\n",
        "        X = np.zeros((len(char_chunks), maxlen, len(self.chars)), dtype=np.bool)\n",
        "        y = np.zeros((len(char_chunks), len(self.chars)), dtype=np.bool)\n",
        "        for i, sentence in enumerate(char_chunks):\n",
        "            for t, char in enumerate(sentence):\n",
        "                X[i, t, self.char_indices[char]] = 1\n",
        "            y[i, self.char_indices[next_char[i]]] = 1\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def build_one_layer_lstm(self, maxlen=40, hidden_units=128, dropout=0, recurrent_dropout=0):\n",
        "        input_shape = (maxlen, len(self.chars))\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(hidden_units, input_shape=input_shape, dropout=dropout, recurrent_dropout=recurrent_dropout))\n",
        "        model.add(Dense(len(self.chars)))\n",
        "        model.add(Activation('softmax'))\n",
        "        optimizer = Adam(lr=0.001)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "        return model\n",
        "    \n",
        "    def build_two_layer_lstm(self, maxlen=40, hidden_units=128):\n",
        "        # Added by Christina\n",
        "        input_shape = (maxlen, len(self.chars))\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(hidden_units, input_shape=input_shape, return_sequences=True))\n",
        "        model.add(LSTM(hidden_units))\n",
        "        model.add(Dense(len(self.chars)))\n",
        "        model.add(Activation('softmax'))\n",
        "        optimizer = Adam(lr=0.001)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "        return model\n",
        "    \n",
        "    def build_cnn_v1(self, maxlen=40, filter_size=5):\n",
        "        input_shape_ = (maxlen, len(self.chars)) + (1,)\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(128, kernel_size=(2, len(self.chars)), activation='relu', input_shape=input_shape_))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv2D(256, kernel_size=(filter_size, 1), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv2D(512, kernel_size=(filter_size, 1), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(len(self.chars)))\n",
        "        model.add(Activation('softmax'))\n",
        "        optimizer = Adam(lr=0.001)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "        return model\n",
        "\n",
        "    def build_cnn_v2(self, maxlen=40):\n",
        "        # Added by Christina, less filtering\n",
        "        input_shape_ = (maxlen, len(self.chars)) + (1,)\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(64, kernel_size=(2, len(self.chars)), activation='relu', input_shape=input_shape_))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv2D(128, kernel_size=(5, 1), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv2D(256, kernel_size=(5, 1), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(len(self.chars)))\n",
        "        model.add(Activation('softmax'))\n",
        "        optimizer = Adam(lr=0.001)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "        return model\n",
        "\n",
        "    def build_cnn_v3(self, maxlen=40):\n",
        "        # Added by Christina, more filtering\n",
        "        input_shape_ = (maxlen, len(self.chars)) + (1,)\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(256, kernel_size=(2, len(self.chars)), activation='relu', input_shape=input_shape_))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv2D(512, kernel_size=(5, 1), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv2D(1024, kernel_size=(5, 1), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(len(self.chars)))\n",
        "        model.add(Activation('softmax'))\n",
        "        optimizer = Adam(lr=0.001)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "        return model\n",
        "    \n",
        "    def build_cnn_v4(self, maxlen=40):\n",
        "        # Added by Qiana, take out a layer\n",
        "        input_shape_ = (40, len(self.chars)) + (1,)\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(128, kernel_size=(2, len(self.chars)), activation='relu', input_shape=input_shape_))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv2D(256, kernel_size=(5, 1), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(len(self.chars)))\n",
        "        model.add(Activation('softmax'))\n",
        "        optimizer = Adam(lr=0.001)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "        return model\n",
        "    \n",
        "    def build_cnn_v5(self, maxlen=40):\n",
        "        # Added by Qiana, add a layer\n",
        "        input_shape_ = (40, len(self.chars)) + (1,)\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(64, kernel_size=(2, len(self.chars)), activation='relu', input_shape=input_shape_))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv2D(128, kernel_size=(5, 1), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv2D(256, kernel_size=(5, 1), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv2D(512, kernel_size=(5, 1), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(len(self.chars)))\n",
        "        model.add(Activation('softmax'))\n",
        "        optimizer = Adam(lr=0.001)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "        return model\n",
        "\n",
        "    # Load existing checkpoint\n",
        "    def load_checkpoint(self, modelname):\n",
        "        if os.path.exists(modelname):\n",
        "            logger.info('Try loading model: %s', modelname)\n",
        "        try:\n",
        "            self.model.load_weights(modelname)\n",
        "            logger.info('Loaded model: %s', modelname)\n",
        "        except Exception:\n",
        "            logger.error('Error in model, not loading...')\n",
        "    \n",
        "    def generate_text(self, maxlen, input_shape, temperature):\n",
        "        start_index = random.randint(0, len(self.text) - maxlen - 1)\n",
        "        for diversity in temperature:\n",
        "            print()\n",
        "            print('----- diversity:', diversity)\n",
        "            viz = np.ndarray((400, len(self.chars)))\n",
        "\n",
        "            generated = ''\n",
        "            sentence = self.text[start_index: start_index + maxlen]\n",
        "            generated += sentence\n",
        "            print('----- Generating with seed: \"' + sentence + '\"')\n",
        "            sys.stdout.write(generated)\n",
        "\n",
        "            for i in range(400):\n",
        "                x = np.zeros((1,) + input_shape)\n",
        "\n",
        "                for t, char in enumerate(sentence):\n",
        "                    x[0, t, self.char_indices[char]] = 1.\n",
        "\n",
        "                preds = self.model.predict(x, verbose=0)[0]\n",
        "                s = self.sample(preds, diversity)\n",
        "                viz[i,:] = s\n",
        "\n",
        "                if i < 5:\n",
        "                    plt.bar(list(range(len(s))), -np.log(s))\n",
        "                    plt.show()\n",
        "                s = np.random.multinomial(1, s, 1)\n",
        "                next_index = np.argmax(s)\n",
        "                next_char = self.indices_char[next_index]\n",
        "\n",
        "                generated += next_char\n",
        "                sentence = sentence[1:] + next_char\n",
        "\n",
        "                sys.stdout.write(next_char)\n",
        "                sys.stdout.flush()\n",
        "                \n",
        "            print()\n",
        "            self.viz_heatmap_chars(viz[:30]) \n",
        "            plt.show(), plt.close()   \n",
        "\n",
        "            plt.imshow(equalize_adapthist(np.log(viz.T+1)), cmap='gray')\n",
        "            plt.title('Visualization of one-hot characters')\n",
        "            plt.grid(False)\n",
        "            plt.show()\n",
        "            plt.close()        \n",
        "        \n",
        "    # used by generate_text\n",
        "    def sample(self, preds, temperature):\n",
        "        \"\"\"helper function to sample an index from a probability array\"\"\"\n",
        "        # helper function to sample an index from a probability array\n",
        "        preds = np.asarray(preds).astype('float64')\n",
        "        preds = np.log(preds) / temperature\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "        return preds\n",
        "\n",
        "    # used by generate_text\n",
        "    def viz_heatmap_chars(self, data, topk=5):\n",
        "        \"\"\"Helpers for visualization\"\"\"\n",
        "        self.charmap = np.zeros((len(data), topk), dtype='str')\n",
        "        self.hmap = np.zeros((len(data), topk))\n",
        "        for d in range(len(data)):\n",
        "            r = np.argsort(-data[d])[:topk]\n",
        "            h = data[d][r]\n",
        "            self.hmap[d] = h\n",
        "            r = list(map(lambda x: self.indices_char[x], r))\n",
        "            self.charmap[d] = np.array(r)\n",
        "        sns.heatmap(self.hmap.T, annot=self.charmap.T, fmt='', cmap='Wistia')\n",
        "        plt.title('Character heatmap')\n",
        "        \n",
        "    def main(self, num_iter: int=600, freq: int=5, modeltype: str='lstm',\n",
        "             save_weights: bool=True, load_weights: bool=False, batch_size: int=128,\n",
        "             epochs: int=1, maxlen: int=40, step: int=1, temperature: list=[0.2, 0.5, 1.0, 1.2],\n",
        "             modelname: str=None):\n",
        "        \n",
        "        if modelname is None:\n",
        "            modelname = 'textgen-figures/' + 'model-text-' + modeltype + '.h5'\n",
        "        \n",
        "        # step 1: preprocess\n",
        "        X, y = self.vectorize(maxlen, step)\n",
        "        if modeltype == 'cnn':\n",
        "            X = np.expand_dims(X, axis=3)\n",
        "        \n",
        "        # optional step: load weights\n",
        "        if load_weights:\n",
        "            self.load_checkpoint(modelname)\n",
        "                \n",
        "        # step 2: train the model, output generated text after each iteration\n",
        "        tm = time.time()\n",
        "        losses = []\n",
        "        for iteration in range(1, num_iter + 1):\n",
        "            print()\n",
        "            print('-' * 50)\n",
        "            print('Iteration', iteration)\n",
        "\n",
        "            history = self.model.fit(X, y, batch_size, epochs)\n",
        "            losses.append(history.history['loss'])\n",
        "\n",
        "            print(\"Total training time: %0.2f min, epoch %d\" % ((time.time() - tm)/60.0, iteration))\n",
        "            print(\"Average time per epoch: %0.2f s\" % ((time.time() - tm)/iteration))\n",
        "\n",
        "            if iteration % freq == 0 and iteration < num_iter:\n",
        "                if save_weights:\n",
        "                    self.model.save_weights(modelname)\n",
        "                input_shape = self.model.layers[0].input_shape[1:]\n",
        "                self.generate_text(maxlen, input_shape, temperature)\n",
        "            \n",
        "            if iteration == num_iter:\n",
        "                if save_weights:\n",
        "                    self.model.save_weights(modelname, overwrite=True)\n",
        "                input_shape = self.model.layers[0].input_shape[1:]\n",
        "                self.generate_text(maxlen, input_shape, temperature)\n",
        "                plt.plot(losses)\n",
        "                plt.yscale('log')\n",
        "                plt.title('Loss')\n",
        "                plt.show()\n",
        "                plt.close()\n",
        "                \n",
        "    def clear(self):\n",
        "        self.charmap = None\n",
        "        self.hmap = None\n",
        "        self.model = None"
      ],
      "id": "ignored-thursday",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QAWO3d_OUqb",
        "outputId": "c5ad293a-1fc7-473b-f58e-37e7b8031727"
      },
      "source": [
        "obj = assign2()"
      ],
      "id": "3QAWO3d_OUqb",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-17 21:29:05,552 my_happy_logger DEBUG    corpus length: 600893\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "instructional-richards"
      },
      "source": [
        "## Problem 1\n",
        "\n",
        "General steps:\n",
        "\n",
        "1) Instantiate class once (unless you want to change the dataset) \\\n",
        "2) configure the model and input shape (either use example model with different parameters, or define a custom model via obj.model = Sequential(), etc.) \\\n",
        "3) call the main method with the right arguments \\\n",
        "4) clear variables\n",
        "\n",
        "For example, here's what you do for Problem 1:"
      ],
      "id": "instructional-richards"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "premium-parent"
      },
      "source": [
        "# obj = assign2()\n",
        "# obj.model = obj.build_one_layer_lstm(maxlen=40)\n",
        "# obj.main(num_iter=1, freq=1, modeltype='lstm', modelname='haha.h5')\n",
        "# obj.clear()"
      ],
      "id": "premium-parent",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "broad-discount"
      },
      "source": [
        "## Problem 2\n",
        "\n",
        "(say you want to change the default temperature values)"
      ],
      "id": "broad-discount"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3mptO77M9jL"
      },
      "source": [
        "# obj.model = obj.build_one_layer_lstm(maxlen=80)\n",
        "# obj.main(maxlen=80, num_iter=25, freq=1, modeltype='lstm', modelname='lstm_maxlen.h5', temperature=[0.3, 2])\n",
        "# obj.clear()"
      ],
      "id": "I3mptO77M9jL",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czech-organic"
      },
      "source": [
        "# obj.model = obj.build_one_layer_lstm(maxlen=80)\n",
        "# obj.main(maxlen=80, num_iter=25, freq=25, modeltype='lstm', modelname='lstm_maxlen.h5')\n",
        "# obj.clear()"
      ],
      "id": "czech-organic",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sticky-wales"
      },
      "source": [
        "## Problem 3"
      ],
      "id": "sticky-wales"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "figured-bradford"
      },
      "source": [
        "### Modification 1"
      ],
      "id": "figured-bradford"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "recorded-nickname"
      },
      "source": [
        "# obj.model = obj.build_one_layer_lstm(hidden_units=64)\n",
        "# obj.main(num_iter=25, freq=25, modelname='q3_1.h5')\n",
        "# obj.clear()"
      ],
      "id": "recorded-nickname",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "academic-session"
      },
      "source": [
        "### Modification 2"
      ],
      "id": "academic-session"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "insured-subscriber"
      },
      "source": [
        "# obj.model = obj.build_one_layer_lstm(hidden_units=256)\n",
        "# obj.main(num_iter=25, freq=10, modeltype='lstm', modelname='q3_2_iter25.h5')\n",
        "# obj.clear()"
      ],
      "id": "insured-subscriber",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "level-shirt"
      },
      "source": [
        "### Modification 3"
      ],
      "id": "level-shirt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adolescent-breakdown"
      },
      "source": [
        "# obj.model = obj.build_one_layer_lstm(dropout=0.2)\n",
        "# obj.main(num_iter=25, freq=25, modelname='q3_3_1.h5')\n",
        "# obj.clear()"
      ],
      "id": "adolescent-breakdown",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "known-captain"
      },
      "source": [
        "# obj.model = obj.build_one_layer_lstm(dropout=0.6)\n",
        "# obj.main(num_iter=25, freq=25, modelname='q3_3_2.h5')\n",
        "# obj.clear()"
      ],
      "id": "known-captain",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "incident-classroom"
      },
      "source": [
        "# obj.model = obj.build_one_layer_lstm(dropout=0.2, recurrent_dropout=0.1)\n",
        "# obj.main(num_iter=25, freq=25, modelname='q3_3_3.h5')\n",
        "# obj.clear()"
      ],
      "id": "incident-classroom",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "heavy-variation"
      },
      "source": [
        "### Modification 4"
      ],
      "id": "heavy-variation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awful-personal"
      },
      "source": [
        "# obj.model = obj.build_two_layer_lstm(maxlen=40, hidden_units=128)\n",
        "# model_name = '/content/drive/MyDrive/Colab Notebooks/432/lstm_4.h5'\n",
        "# obj.main(num_iter=25, freq=2, modeltype='lstm', modelname=model_name)\n",
        "# obj.clear()"
      ],
      "id": "awful-personal",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "marked-reproduction"
      },
      "source": [
        "### Modification 5"
      ],
      "id": "marked-reproduction"
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "efficient-nelson"
      },
      "source": [
        "# input_shape = (40, len(obj.chars))\n",
        "# obj.model = Sequential([\n",
        "    # LSTM(64, input_shape=input_shape),\n",
        "    # Dense(len(obj.chars)),\n",
        "    # Activation('softmax')\n",
        "# ])\n",
        "# optimizer = Adam(lr=0.001)\n",
        "# obj.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "# obj.main(num_iter = 10, freq = 5, modeltype = 'lstm')\n",
        "# obj.clear()"
      ],
      "id": "efficient-nelson",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "middle-illness"
      },
      "source": [
        "# input_shape = (40, len(obj.chars))\n",
        "# obj.model = Sequential([\n",
        "    # GRU(64, input_shape=input_shape),\n",
        "    # Dense(len(obj.chars)),\n",
        "    # Activation('softmax')\n",
        "# ])\n",
        "# optimizer = Adam(lr=0.001)\n",
        "# obj.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "# obj.main(num_iter = 25, freq = 5, modeltype = 'gru')\n",
        "# obj.clear()"
      ],
      "id": "middle-illness",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "proved-reverse"
      },
      "source": [
        "## Problem 4\n",
        "\n",
        "Here's how you can configure your model outside the class (alternatively, you can define a new method inside the class):"
      ],
      "id": "proved-reverse"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dynamic-buying"
      },
      "source": [
        "# input_shape = (40, len(obj.chars))\n",
        "# obj.model = Sequential()\n",
        "# obj.model.add(LSTM(64, input_shape=input_shape))\n",
        "# obj.model.add(Dense(len(obj.chars)))\n",
        "# obj.model.add(Activation('softmax'))\n",
        "# optimizer = Adam(lr=0.001)\n",
        "# obj.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "# obj.main()\n",
        "# obj.clear()\n",
        "\n",
        "# # this is equivalent to the following:\n",
        "# obj.model = obj.build_one_layer_lstm(maxlen=40, hidden_units=64)\n",
        "# obj.main()\n",
        "# obj.clear()"
      ],
      "id": "dynamic-buying",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "instant-liabilities",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Mix 1"
      ],
      "id": "instant-liabilities"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "least-paragraph",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# input_shape = (40, len(obj.chars))\n",
        "# obj.model = Sequential([\n",
        "#     Bidirectional(LSTM(64, return_sequences=True, dropout=0.1, recurrent_dropout=0), \n",
        "#                   input_shape=input_shape),\n",
        "#     BatchNormalization(),\n",
        "#     Bidirectional(GRU(32, dropout=0.01, recurrent_dropout=0)),\n",
        "#     BatchNormalization(),\n",
        "#     Dense(len(obj_q4_1.chars), activation='softmax')\n",
        "# ])\n",
        "# optimizer = Adam(lr=0.001)\n",
        "# obj.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "# obj.main(num_iter=25, freq=10, modeltype='lstm')\n",
        "# obj.clear()"
      ],
      "id": "least-paragraph",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "previous-liquid"
      },
      "source": [
        "### Mix 2"
      ],
      "id": "previous-liquid"
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "harmful-processing"
      },
      "source": [
        "# input_shape = (80, len(obj.chars))\n",
        "# obj.model = Sequential([\n",
        "#    Bidirectional(LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0),\n",
        "#                  input_shape=input_shape),\n",
        "#    BatchNormalization(),\n",
        "#    Bidirectional(GRU(64, dropout=0.1, recurrent_dropout=0)),\n",
        "#    BatchNormalization(),\n",
        "#    Dense(57, activation='softmax')\n",
        "# ])\n",
        "# optimizer = Adam(lr=0.001)\n",
        "# obj.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "# obj.main(maxlen=80, num_iter=25, freq=25, modelname='q3_3_3.h5')\n",
        "# obj.clear()"
      ],
      "id": "harmful-processing",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "radio-experience",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Problem 5 - CNN"
      ],
      "id": "radio-experience"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "advised-voluntary"
      },
      "source": [
        "### Part A"
      ],
      "id": "advised-voluntary"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apart-singles"
      },
      "source": [
        "# obj.model = obj.build_cnn_v1(filter_size=7)\n",
        "# obj.main(num_iter=25, modelname= \"CNN_filter_7\",modeltype='cnn')\n",
        "# obj.clear()"
      ],
      "id": "apart-singles",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "disturbed-slide"
      },
      "source": [
        "# obj.model = obj.build_cnn_v1(filter_size=3)\n",
        "# obj.main(num_iter=25, modelname= \"CNN_filter_3\",modeltype='cnn')\n",
        "# obj.clear()"
      ],
      "id": "disturbed-slide",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tight-administrator"
      },
      "source": [
        "# obj.model = obj.build_cnn_v1(filter_size=5)\n",
        "# obj.main(num_iter=25, modelname= \"CNN_filter_5\",modeltype='cnn')\n",
        "# obj.clear()"
      ],
      "id": "tight-administrator",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "authentic-confidentiality"
      },
      "source": [
        "### Part B"
      ],
      "id": "authentic-confidentiality"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "starting-server"
      },
      "source": [
        "# obj.model = obj.build_cnn_v2()\n",
        "# model_name = '/content/drive/MyDrive/Colab Notebooks/432/{model_name}.h5'\n",
        "# obj.main(num_iter=25, freq=2, modeltype='cnn', modelname=model_name)\n",
        "# obj.clear()"
      ],
      "id": "starting-server",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "going-maryland"
      },
      "source": [
        "# obj.model = obj.build_cnn_v3()\n",
        "# model_name = '/content/drive/MyDrive/Colab Notebooks/432/{model_name}.h5'\n",
        "# obj.main(num_iter=25, freq=2, modeltype='cnn', modelname=model_name)\n",
        "# obj.clear()"
      ],
      "id": "going-maryland",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "outer-mortality"
      },
      "source": [
        "### Part C"
      ],
      "id": "outer-mortality"
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "legendary-rover"
      },
      "source": [
        "# obj.model = obj.build_cnn_v4()\n",
        "# obj.main(maxlen=40, num_iter=25, freq=25, modeltype='cnn', modelname='cnn_no_last_layer.h5')\n",
        "# obj.clear()"
      ],
      "id": "legendary-rover",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rapid-dream"
      },
      "source": [
        "# obj.model = obj.build_cnn_v5()\n",
        "# obj.main(maxlen=40, num_iter=25, freq=25, modeltype='cnn', modelname='cnn_add_first_layer.h5')\n",
        "# obj.clear()"
      ],
      "id": "rapid-dream",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "touched-boring"
      },
      "source": [
        "### Part D"
      ],
      "id": "touched-boring"
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wireless-consumer"
      },
      "source": [
        "# filter_size_collection = []\n",
        "# filter_number_collection = []\n",
        "# loss_collection = []\n",
        "# time_collection = []\n",
        "\n",
        "# for filter_size in [7,9,11]:\n",
        "#     for filter_number in [64, 128, 256]:\n",
        "#         obj.model = obj.build_cnn_v1(maxlen=40, filter_size=filter_size, filter_number=filter_number)\n",
        "#         obj.main(num_iter=30, freq=30, modeltype='cnn')\n",
        "#         filter_size_collection.append(filter_size)\n",
        "#         filter_number_collection.append(filter_number)\n",
        "#         loss_collection.append(obj.final_loss)\n",
        "#         time_collection.append(obj.total_time)\n",
        "#         obj.clear()"
      ],
      "id": "wireless-consumer",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "seventh-cathedral"
      },
      "source": [
        "Then we want to test if adding another layer makes significant difference"
      ],
      "id": "seventh-cathedral"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acceptable-tiger"
      },
      "source": [
        "# filter_size_collection = []\n",
        "# filter_number_collection = []\n",
        "# loss_collection = []\n",
        "# time_collection = []\n",
        "\n",
        "# for filter_size in [7, 9]:\n",
        "#     for filter_number in [32, 64, 128]:\n",
        "#         obj.model = obj.build_cnn_v2(maxlen=40, filter_size=filter_size, filter_number=filter_number)\n",
        "#         obj.main(num_iter=30, freq=40, modeltype='cnn')\n",
        "#         filter_size_collection.append(filter_size)\n",
        "#         filter_number_collection.append(filter_number)\n",
        "#         loss_collection.append(obj.final_loss)\n",
        "#         time_collection.append(obj.total_time)\n",
        "#         obj.clear()"
      ],
      "id": "acceptable-tiger",
      "execution_count": 31,
      "outputs": []
    }
  ]
}
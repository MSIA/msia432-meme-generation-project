{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "designed-paintball",
   "metadata": {
    "id": "australian-jacob"
   },
   "source": [
    "# Assignment2b - V.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vulnerable-frame",
   "metadata": {
    "id": "closing-boating"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys, time, random, gc, socket\n",
    "import logging\n",
    "from collections import Counter\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.exposure import equalize_adapthist\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import LSTM, Conv2D, Bidirectional, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greatest-program",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sticky-examination",
    "outputId": "bf603251-3e38-4d1e-8949-703c0db5917e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM GPUS: 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "else:\n",
    "  print('NUM GPUS:', len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dependent-northeast",
   "metadata": {
    "id": "compressed-settlement"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('my_happy_logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "damaged-omaha",
   "metadata": {
    "id": "great-while"
   },
   "outputs": [],
   "source": [
    "# GPU memory fix + Mac workaround\n",
    "if not IS_COLAB:\n",
    "    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hairy-touch",
   "metadata": {
    "id": "every-stamp"
   },
   "outputs": [],
   "source": [
    "os.makedirs('textgen-figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "social-jewelry",
   "metadata": {
    "id": "frank-criterion"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incorporate-confusion",
   "metadata": {
    "id": "ignored-thursday"
   },
   "outputs": [],
   "source": [
    "class assign2:\n",
    "    \n",
    "    def __init__(self, filename='nietzsche.txt', \n",
    "                 filepath='https://s3.amazonaws.com/text-datasets/nietzsche.txt'):\n",
    "        \n",
    "        # saving static variables in __init__\n",
    "        self.text = self.download_file(filename, filepath)\n",
    "        self.chars = dict(sorted(Counter(self.text).items(), key=lambda x:x[1], reverse=True)).keys()\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        \n",
    "        # dyanmic variables - these are the variables that need to be changed via clear() after each modeling process\n",
    "        self.charmap = None\n",
    "        self.hmap = None\n",
    "        self.model = None\n",
    "        \n",
    "    def download_file(self, filename, filepath):\n",
    "        path = get_file(filename, filepath)\n",
    "        text = open(path).read().lower()\n",
    "        logger.debug(f'corpus length: {len(text)}')\n",
    "        return text\n",
    "        \n",
    "    def tokenize(self, maxlen, step):\n",
    "        \n",
    "        # break text into equal-length chunks\n",
    "        char_chunks = [self.text[i: i + maxlen] for i in range(0, len(self.text) - maxlen, step)]\n",
    "        next_char = [self.text[i + maxlen] for i in range(0, len(self.text) - maxlen, step)]\n",
    "        logger.debug(f'nb sequences: {len(char_chunks)}')\n",
    "        \n",
    "        return char_chunks, next_char\n",
    "        \n",
    "    def vectorize(self, maxlen, step):\n",
    "        char_chunks, next_char = self.tokenize(maxlen, step)\n",
    "        X = np.zeros((len(char_chunks), maxlen, len(self.chars)), dtype=np.bool)\n",
    "        y = np.zeros((len(char_chunks), len(self.chars)), dtype=np.bool)\n",
    "        for i, sentence in enumerate(char_chunks):\n",
    "            for t, char in enumerate(sentence):\n",
    "                X[i, t, self.char_indices[char]] = 1\n",
    "            y[i, self.char_indices[next_char[i]]] = 1\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def build_one_layer_lstm(self, maxlen=40, hidden_units=128, dropout=0, recurrent_dropout=0):\n",
    "        input_shape = (maxlen, len(self.chars))\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(hidden_units, input_shape=input_shape, dropout=dropout, recurrent_dropout=recurrent_dropout))\n",
    "        model.add(Dense(len(self.chars)))\n",
    "        model.add(Activation('softmax'))\n",
    "        optimizer = Adam(lr=0.001)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "        return model\n",
    "    \n",
    "    def build_two_layer_lstm(self, maxlen=40, hidden_units=128):\n",
    "        # Added by Christina\n",
    "        input_shape = (maxlen, len(self.chars))\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(hidden_units, input_shape=input_shape, return_sequences=True))\n",
    "        model.add(LSTM(hidden_units))\n",
    "        model.add(Dense(len(self.chars)))\n",
    "        model.add(Activation('softmax'))\n",
    "        optimizer = Adam(lr=0.001)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "        return model\n",
    "    \n",
    "    def build_cnn_v1(self, maxlen=40, filter_size=5):\n",
    "        input_shape_ = (maxlen, len(self.chars)) + (1,)\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(128, kernel_size=(2, len(self.chars)), activation='relu', input_shape=input_shape_))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(256, kernel_size=(filter_size, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(512, kernel_size=(filter_size, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(len(self.chars)))\n",
    "        model.add(Activation('softmax'))\n",
    "        optimizer = Adam(lr=0.001)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "        return model\n",
    "\n",
    "    def build_cnn_v2(self, maxlen=40):\n",
    "        # Added by Christina, less filtering\n",
    "        input_shape_ = (maxlen, len(self.chars)) + (1,)\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, kernel_size=(2, len(self.chars)), activation='relu', input_shape=input_shape_))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(128, kernel_size=(5, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(256, kernel_size=(5, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(len(self.chars)))\n",
    "        model.add(Activation('softmax'))\n",
    "        optimizer = Adam(lr=0.001)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "        return model\n",
    "\n",
    "    def build_cnn_v3(self, maxlen=40):\n",
    "        # Added by Christina, more filtering\n",
    "        input_shape_ = (maxlen, len(self.chars)) + (1,)\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(256, kernel_size=(2, len(self.chars)), activation='relu', input_shape=input_shape_))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(512, kernel_size=(5, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(1024, kernel_size=(5, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(len(self.chars)))\n",
    "        model.add(Activation('softmax'))\n",
    "        optimizer = Adam(lr=0.001)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "        return model\n",
    "    \n",
    "    def build_cnn_v4(self, maxlen=40):\n",
    "        # Added by Qiana, take out a layer\n",
    "        input_shape_ = (40, len(self.chars)) + (1,)\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(128, kernel_size=(2, len(self.chars)), activation='relu', input_shape=input_shape_))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(256, kernel_size=(5, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(len(self.chars)))\n",
    "        model.add(Activation('softmax'))\n",
    "        optimizer = Adam(lr=0.001)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "        return model\n",
    "    \n",
    "    def build_cnn_v5(self, maxlen=40):\n",
    "        # Added by Qiana, add a layer\n",
    "        input_shape_ = (40, len(self.chars)) + (1,)\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, kernel_size=(2, len(self.chars)), activation='relu', input_shape=input_shape_))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(128, kernel_size=(5, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(256, kernel_size=(5, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(512, kernel_size=(5, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(len(self.chars)))\n",
    "        model.add(Activation('softmax'))\n",
    "        optimizer = Adam(lr=0.001)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "        return model\n",
    "\n",
    "    # Load existing checkpoint\n",
    "    def load_checkpoint(self, modelname):\n",
    "        if os.path.exists(modelname):\n",
    "            logger.info('Try loading model: %s', modelname)\n",
    "        try:\n",
    "            self.model.load_weights(modelname)\n",
    "            logger.info('Loaded model: %s', modelname)\n",
    "        except Exception:\n",
    "            logger.error('Error in model, not loading...')\n",
    "    \n",
    "    def generate_text(self, maxlen, input_shape, temperature):\n",
    "        start_index = random.randint(0, len(self.text) - maxlen - 1)\n",
    "        for diversity in temperature:\n",
    "            print()\n",
    "            print('----- diversity:', diversity)\n",
    "            viz = np.ndarray((400, len(self.chars)))\n",
    "\n",
    "            generated = ''\n",
    "            sentence = self.text[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print('----- Generating with seed: \"' + sentence + '\"')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(400):\n",
    "                x = np.zeros((1,) + input_shape)\n",
    "\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x[0, t, self.char_indices[char]] = 1.\n",
    "\n",
    "                preds = self.model.predict(x, verbose=0)[0]\n",
    "                s = self.sample(preds, diversity)\n",
    "                viz[i,:] = s\n",
    "\n",
    "                if i < 5:\n",
    "                    plt.bar(list(range(len(s))), -np.log(s))\n",
    "                    plt.show()\n",
    "                s = np.random.multinomial(1, s, 1)\n",
    "                next_index = np.argmax(s)\n",
    "                next_char = self.indices_char[next_index]\n",
    "\n",
    "                generated += next_char\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "            print()\n",
    "            self.viz_heatmap_chars(viz[:30]) \n",
    "            plt.show(), plt.close()   \n",
    "\n",
    "            plt.imshow(equalize_adapthist(np.log(viz.T+1)), cmap='gray')\n",
    "            plt.title('Visualization of one-hot characters')\n",
    "            plt.grid(False)\n",
    "            plt.show()\n",
    "            plt.close()        \n",
    "        \n",
    "    # used by generate_text\n",
    "    def sample(self, preds, temperature):\n",
    "        \"\"\"helper function to sample an index from a probability array\"\"\"\n",
    "        # helper function to sample an index from a probability array\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        return preds\n",
    "\n",
    "    # used by generate_text\n",
    "    def viz_heatmap_chars(self, data, topk=5):\n",
    "        \"\"\"Helpers for visualization\"\"\"\n",
    "        self.charmap = np.zeros((len(data), topk), dtype='str')\n",
    "        self.hmap = np.zeros((len(data), topk))\n",
    "        for d in range(len(data)):\n",
    "            r = np.argsort(-data[d])[:topk]\n",
    "            h = data[d][r]\n",
    "            self.hmap[d] = h\n",
    "            r = list(map(lambda x: self.indices_char[x], r))\n",
    "            self.charmap[d] = np.array(r)\n",
    "        sns.heatmap(self.hmap.T, annot=self.charmap.T, fmt='', cmap='Wistia')\n",
    "        plt.title('Character heatmap')\n",
    "        \n",
    "    def main(self, num_iter: int=600, freq: int=5, modeltype: str='lstm',\n",
    "             save_weights: bool=True, load_weights: bool=False, batch_size: int=128,\n",
    "             epochs: int=1, maxlen: int=40, step: int=1, temperature: list=[0.2, 0.5, 1.0, 1.2],\n",
    "             modelname: str=None):\n",
    "        \n",
    "        if modelname is None:\n",
    "            modelname = 'textgen-figures/' + 'model-text-' + modeltype + '.h5'\n",
    "        \n",
    "        # step 1: preprocess\n",
    "        X, y = self.vectorize(maxlen, step)\n",
    "        if modeltype == 'cnn':\n",
    "            X = np.expand_dims(X, axis=3)\n",
    "        \n",
    "        # optional step: load weights\n",
    "        if load_weights:\n",
    "            self.load_checkpoint(modelname)\n",
    "                \n",
    "        # step 2: train the model, output generated text after each iteration\n",
    "        tm = time.time()\n",
    "        losses = []\n",
    "        for iteration in range(1, num_iter + 1):\n",
    "            print()\n",
    "            print('-' * 50)\n",
    "            print('Iteration', iteration)\n",
    "\n",
    "            history = self.model.fit(X, y, batch_size, epochs)\n",
    "            losses.append(history.history['loss'])\n",
    "\n",
    "            print(\"Total training time: %0.2f min, epoch %d\" % ((time.time() - tm)/60.0, iteration))\n",
    "            print(\"Average time per epoch: %0.2f s\" % ((time.time() - tm)/iteration))\n",
    "\n",
    "            if iteration % freq == 0 and iteration < num_iter:\n",
    "                if save_weights:\n",
    "                    self.model.save_weights(modelname)\n",
    "                input_shape = self.model.layers[0].input_shape[1:]\n",
    "                self.generate_text(maxlen, input_shape, temperature)\n",
    "            \n",
    "            if iteration == num_iter:\n",
    "                if save_weights:\n",
    "                    self.model.save_weights(modelname, overwrite=True)\n",
    "                input_shape = self.model.layers[0].input_shape[1:]\n",
    "                self.generate_text(maxlen, input_shape, temperature)\n",
    "                plt.plot(losses)\n",
    "                plt.yscale('log')\n",
    "                plt.title('Loss')\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                \n",
    "    def clear(self):\n",
    "        self.charmap = None\n",
    "        self.hmap = None\n",
    "        self.model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "therapeutic-reporter",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3QAWO3d_OUqb",
    "outputId": "c5ad293a-1fc7-473b-f58e-37e7b8031727"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-17 21:29:05,552 my_happy_logger DEBUG    corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "obj = assign2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-masters",
   "metadata": {
    "id": "instructional-richards"
   },
   "source": [
    "## Problem 1\n",
    "\n",
    "General steps:\n",
    "\n",
    "1) Instantiate class once (unless you want to change the dataset) \\\n",
    "2) configure the model and input shape (either use example model with different parameters, or define a custom model via obj.model = Sequential(), etc.) \\\n",
    "3) call the main method with the right arguments \\\n",
    "4) clear variables\n",
    "\n",
    "For example, here's what you do for Problem 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "commercial-slovenia",
   "metadata": {
    "id": "premium-parent"
   },
   "outputs": [],
   "source": [
    "# obj = assign2()\n",
    "# obj.model = obj.build_one_layer_lstm(maxlen=40)\n",
    "# obj.main(num_iter=1, freq=1, modeltype='lstm', modelname='haha.h5')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-treasure",
   "metadata": {
    "id": "broad-discount"
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "(say you want to change the default temperature values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "british-range",
   "metadata": {
    "id": "I3mptO77M9jL"
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_one_layer_lstm(maxlen=80)\n",
    "# obj.main(maxlen=80, num_iter=25, freq=1, modeltype='lstm', modelname='lstm_maxlen.h5', temperature=[0.3, 2])\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "intellectual-timer",
   "metadata": {
    "id": "czech-organic"
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_one_layer_lstm(maxlen=80)\n",
    "# obj.main(maxlen=80, num_iter=25, freq=25, modeltype='lstm', modelname='lstm_maxlen.h5')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-patch",
   "metadata": {
    "id": "sticky-wales"
   },
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-smart",
   "metadata": {
    "id": "figured-bradford"
   },
   "source": [
    "### Modification 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "leading-scout",
   "metadata": {
    "id": "recorded-nickname"
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_one_layer_lstm(hidden_units=64)\n",
    "# obj.main(num_iter=25, freq=25, modelname='q3_1.h5')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-triangle",
   "metadata": {
    "id": "academic-session"
   },
   "source": [
    "### Modification 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "noted-memory",
   "metadata": {
    "id": "insured-subscriber"
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_one_layer_lstm(hidden_units=256)\n",
    "# obj.main(num_iter=25, freq=10, modeltype='lstm', modelname='q3_2_iter25.h5')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-payment",
   "metadata": {
    "id": "level-shirt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Modification 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "silver-concrete",
   "metadata": {
    "id": "adolescent-breakdown"
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_one_layer_lstm(dropout=0.2)\n",
    "# obj.main(num_iter=25, freq=25, modelname='q3_3_1.h5')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "equipped-drunk",
   "metadata": {
    "id": "known-captain"
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_one_layer_lstm(dropout=0.6)\n",
    "# obj.main(num_iter=25, freq=25, modelname='q3_3_2.h5')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "complicated-stand",
   "metadata": {
    "id": "incident-classroom",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_one_layer_lstm(dropout=0.2, recurrent_dropout=0.1)\n",
    "# obj.main(num_iter=25, freq=25, modelname='q3_3_3.h5')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-madison",
   "metadata": {
    "id": "heavy-variation",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Modification 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "musical-adrian",
   "metadata": {
    "id": "awful-personal"
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_two_layer_lstm(maxlen=40, hidden_units=128)\n",
    "# model_name = '/content/drive/MyDrive/Colab Notebooks/432/lstm_4.h5'\n",
    "# obj.main(num_iter=25, freq=2, modeltype='lstm', modelname=model_name)\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-statistics",
   "metadata": {
    "id": "marked-reproduction",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Modification 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "configured-offset",
   "metadata": {
    "id": "efficient-nelson",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input_shape = (40, len(obj.chars))\n",
    "# obj.model = Sequential([\n",
    "    # LSTM(64, input_shape=input_shape),\n",
    "    # Dense(len(obj.chars)),\n",
    "    # Activation('softmax')\n",
    "# ])\n",
    "# optimizer = Adam(lr=0.001)\n",
    "# obj.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# obj.main(num_iter = 10, freq = 5, modeltype = 'lstm')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "olympic-playback",
   "metadata": {
    "id": "middle-illness"
   },
   "outputs": [],
   "source": [
    "# input_shape = (40, len(obj.chars))\n",
    "# obj.model = Sequential([\n",
    "    # GRU(64, input_shape=input_shape),\n",
    "    # Dense(len(obj.chars)),\n",
    "    # Activation('softmax')\n",
    "# ])\n",
    "# optimizer = Adam(lr=0.001)\n",
    "# obj.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# obj.main(num_iter = 25, freq = 5, modeltype = 'gru')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-layer",
   "metadata": {
    "id": "proved-reverse"
   },
   "source": [
    "## Problem 4\n",
    "\n",
    "Here's how you can configure your model outside the class (alternatively, you can define a new method inside the class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "thermal-column",
   "metadata": {
    "id": "dynamic-buying"
   },
   "outputs": [],
   "source": [
    "# input_shape = (40, len(obj.chars))\n",
    "# obj.model = Sequential()\n",
    "# obj.model.add(LSTM(64, input_shape=input_shape))\n",
    "# obj.model.add(Dense(len(obj.chars)))\n",
    "# obj.model.add(Activation('softmax'))\n",
    "# optimizer = Adam(lr=0.001)\n",
    "# obj.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# obj.main()\n",
    "# obj.clear()\n",
    "\n",
    "# # this is equivalent to the following:\n",
    "# obj.model = obj.build_one_layer_lstm(maxlen=40, hidden_units=64)\n",
    "# obj.main()\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-stocks",
   "metadata": {
    "id": "instant-liabilities",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Mix 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "attempted-austin",
   "metadata": {
    "id": "least-paragraph",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input_shape = (40, len(obj.chars))\n",
    "# obj.model = Sequential([\n",
    "#     Bidirectional(LSTM(64, return_sequences=True, dropout=0.1, recurrent_dropout=0), \n",
    "#                   input_shape=input_shape),\n",
    "#     BatchNormalization(),\n",
    "#     Bidirectional(GRU(32, dropout=0.01, recurrent_dropout=0)),\n",
    "#     BatchNormalization(),\n",
    "#     Dense(len(obj.chars), activation='softmax')\n",
    "# ])\n",
    "# optimizer = Adam(lr=0.001)\n",
    "# obj.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# obj.main(num_iter=25, freq=10, modeltype='lstm')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-gather",
   "metadata": {
    "id": "previous-liquid",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Mix 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "twelve-economics",
   "metadata": {
    "id": "harmful-processing",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input_shape = (80, len(obj.chars))\n",
    "# obj.model = Sequential([\n",
    "#    Bidirectional(LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0),\n",
    "#                  input_shape=input_shape),\n",
    "#    BatchNormalization(),\n",
    "#    Bidirectional(GRU(64, dropout=0.1, recurrent_dropout=0)),\n",
    "#    BatchNormalization(),\n",
    "#    Dense(57, activation='softmax')\n",
    "# ])\n",
    "# optimizer = Adam(lr=0.001)\n",
    "# obj.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# obj.main(maxlen=80, num_iter=25, freq=25, modelname='q3_3_3.h5')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-consequence",
   "metadata": {
    "id": "radio-experience",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem 5 - CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-survivor",
   "metadata": {
    "id": "advised-voluntary",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "healthy-slovak",
   "metadata": {
    "id": "apart-singles"
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_cnn_v1(filter_size=7)\n",
    "# obj.main(num_iter=25, modelname= \"CNN_filter_7\",modeltype='cnn')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "residential-affect",
   "metadata": {
    "id": "disturbed-slide",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_cnn_v1(filter_size=3)\n",
    "# obj.main(num_iter=25, modelname= \"CNN_filter_3\",modeltype='cnn')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unsigned-candle",
   "metadata": {
    "id": "tight-administrator",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_cnn_v1(filter_size=5)\n",
    "# obj.main(num_iter=25, modelname= \"CNN_filter_5\",modeltype='cnn')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-thesis",
   "metadata": {
    "id": "authentic-confidentiality"
   },
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "phantom-polls",
   "metadata": {
    "id": "starting-server"
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_cnn_v2()\n",
    "# model_name = '/content/drive/MyDrive/Colab Notebooks/432/{model_name}.h5'\n",
    "# obj.main(num_iter=25, freq=2, modeltype='cnn', modelname=model_name)\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eleven-customs",
   "metadata": {
    "id": "going-maryland"
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_cnn_v3()\n",
    "# model_name = '/content/drive/MyDrive/Colab Notebooks/432/{model_name}.h5'\n",
    "# obj.main(num_iter=25, freq=2, modeltype='cnn', modelname=model_name)\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-postcard",
   "metadata": {
    "id": "outer-mortality",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "serial-trance",
   "metadata": {
    "id": "legendary-rover",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_cnn_v4()\n",
    "# obj.main(maxlen=40, num_iter=25, freq=25, modeltype='cnn', modelname='cnn_no_last_layer.h5')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "twelve-bicycle",
   "metadata": {
    "id": "rapid-dream"
   },
   "outputs": [],
   "source": [
    "# obj.model = obj.build_cnn_v5()\n",
    "# obj.main(maxlen=40, num_iter=25, freq=25, modeltype='cnn', modelname='cnn_add_first_layer.h5')\n",
    "# obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-saudi",
   "metadata": {
    "id": "touched-boring",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "announced-founder",
   "metadata": {
    "id": "wireless-consumer",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# filter_size_collection = []\n",
    "# filter_number_collection = []\n",
    "# loss_collection = []\n",
    "# time_collection = []\n",
    "\n",
    "# for filter_size in [7,9,11]:\n",
    "#     for filter_number in [64, 128, 256]:\n",
    "#         obj.model = obj.build_cnn_v1(maxlen=40, filter_size=filter_size, filter_number=filter_number)\n",
    "#         obj.main(num_iter=30, freq=30, modeltype='cnn')\n",
    "#         filter_size_collection.append(filter_size)\n",
    "#         filter_number_collection.append(filter_number)\n",
    "#         loss_collection.append(obj.final_loss)\n",
    "#         time_collection.append(obj.total_time)\n",
    "#         obj.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-arrangement",
   "metadata": {
    "id": "seventh-cathedral",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then we want to test if adding another layer makes significant difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "included-monday",
   "metadata": {
    "id": "acceptable-tiger"
   },
   "outputs": [],
   "source": [
    "# filter_size_collection = []\n",
    "# filter_number_collection = []\n",
    "# loss_collection = []\n",
    "# time_collection = []\n",
    "\n",
    "# for filter_size in [7, 9]:\n",
    "#     for filter_number in [32, 64, 128]:\n",
    "#         obj.model = obj.build_cnn_v2(maxlen=40, filter_size=filter_size, filter_number=filter_number)\n",
    "#         obj.main(num_iter=30, freq=40, modeltype='cnn')\n",
    "#         filter_size_collection.append(filter_size)\n",
    "#         filter_number_collection.append(filter_number)\n",
    "#         loss_collection.append(obj.final_loss)\n",
    "#         time_collection.append(obj.total_time)\n",
    "#         obj.clear()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "assignment2b_v2.ipynb",
   "provenance": []
  },
  "jupytext": {
   "comment_magics": false,
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
